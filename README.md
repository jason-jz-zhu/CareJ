# CareJ
# Problem

CareJourney manages millions of patient lives with billions of encounters. Processing this data efficiently
while maintaining flexibility is core to our success. To that end, this challenge is designed to learn how
you approach data ingestion and processing to fuel analytics applications at scale.


# Tech Stack

I am using following platform and data strutures:

* [Python 3.6] - Main programing language
* [Spyder] - GUI
* [Basic Data Strutures] - Array, Hashmap etc


# Executate Code

1. Move to the root of project
1. Run one of following code:
$ ./run.sh
python ./src/workflow.py ../input/npi_nppes_data_r201610.csv 500
